\documentclass[11pt, openany]{book}              % Book class in 11 points
\parindent0pt  \parskip10pt             % make block paragraphs
\raggedright                            % do not right justify


\title{\bf Machine Learning Handbook}    % Supply information
\author{Xinhe Liu}              %   for the title page.
\date{2018-2-28}                           %   Use current date. 

% Note that book class by default is formatted to be printed back-to-back.
\begin{document}                        % End of preamble, start of text.
% \frontmatter                            % only in book class (roman page #s)
\maketitle                              % Print title page.
\tableofcontents                        % Print table of contents
\mainmatter                             % only in book class (arabic page #s)

\part{High-level Views}
\chapter{Math Review}

\section{Linear Algebra}

Concepts:

\begin{itemize}
    \item scalar, vector, matrix, tensor(n-rank tensor, matrix is a rank 2 tensor) 
    \item Gaussian Elimination, rank
    \item p-norm $$|X|_p = (\sum_i |x_i|^p)^{\frac{1}{p}}$$
    \item inner product$<x_i,y_i>$, outer product
    \item orthogonal，dimension, basis, orthogonal basis
    \item linear transformation $Ax = y$
    \item eigenvalue, eigenvector $Ax =\lambda x$ (transformation and speed)
    \item vector space, linear space(with summation, scalar production), inner product space( inner product space) 
\end{itemize}


\section{Probability}

Concepts:

\begin{itemize}
    \item Classic Probability Model: Frequentist 
    \item Bayesian Probability Theory 
    \item Random variable, continuous RV, discrete RV, probability mass function, probability density function, cumulative density function
    \item Bernoulli distribution, Binomial distribution(n,p)$$P(X=k) = {N\choose k} p^k (1-p)^{(n-k)}$$, Poisson distribution $$P(X=k) = \lambda^k \frac{e^{-\lambda}}{k!}$$
    \item uniform distribution, exponential distribution $$e^{-\frac{x}{\theta}}\theta, P(x>s+t|X>s) = P(x>t)$$, normal distribution, t-distribution
    \item expectation, moments, variance, covariance, correlation coefficient
\end{itemize}


Theorems:

\begin{itemize}
    \item Law of Total Probability
    \item Bayesian Theorem $$P(H|D) = \frac{P(D|H) P(H)}{P(D)}$$ P(H)-prior probability, P(D|H)-likelihood, P(H|D)-posterior probability,
\end{itemize}

\section{Statistics}

Concepts:

\begin{itemize}
    \item data, sample, statistics, population
    \item point estimation, interval estimation, confidence interval(intepreation??)
    \item method of moments: $E(X^k)$ based on LOLN.
    \item maximum likelihood estimation. Multiply p.m.f/p.d.f since every sample is independent. Maximize the likelihood of finding samples. 
    \item Estimation criteria
   		\begin{itemize}
   		 \item unbiased
   		 \item efficient
   		 \item coherent
   		\end{itemize}
   	\item Hypotheis test, type-I error(wrongly reject), type-II error(wrongly accept)
\end{itemize}


Theorems:

\begin{itemize}
    \item Law of Large Number
    \item Central Limit Theorem
        \item Bias/Variance decomposition (error = bias + variance + noise)
        $$E[(Y-\hat{\mu}(X))^2]  = = E[(Y-f(x) + f(x) -\hat{\mu}(X))^2]$$
    $$= E[(Y-f(x)]^2 + 2E[(Y-f(x))(f(x) - \hat{\mu}(X))] + E[(f(x)-\hat{\mu}(X))^2]$$
    $$ =\sigma_x^2 + Bias(\hat{\mu}(X))^2 + Var(\hat{\mu}(X))$$
 
\end{itemize}
 
 
\section{Optimization Theory}

\begin{itemize}
    \item Objective function/Evaluation function, constrained/unconstrained optimization，Feasible Set, Optimal Solution, Optimal Value, Binding Constraints, Shadow Price, Infeasible Price, Infeasibility, Unboundedness    
    \item Linear Programming
    \item Lagrange Multiplier $$L(x,y,\lambda) = f(x,y) + \lambda \varphi(x,y) $$
    \item Convex Set, Convex Function $f:S\to R$ is convex if and only if $\bigtriangledown^2 f(\mathbf{x})$ is positive semidefinite 
\end{itemize}

Optimization Methods:
\begin{itemize}
    \item Linear Search Method: Direction First, Step Size second	
    	\begin{itemize}  		
    		\item Gradient Descent: Batch Processing(Use all samples) vs Stochastic Gradient Descent(Use one sample)
    		\item Newton's Method: Use Curvature Information 
   		\end{itemize}
   	\item Trust Region: Step first, direction second. Find optimal direction of second-order approximation. If the descent size is too small, make step size smaller.
   	\item Heuristics Method
   		\begin{itemize}  		
	    	\item Genetic Algorithm
	 	   	\item Simulated Annealing 
	    	\item Partical Swarming/Ant Colony Algorithm
	    \end{itemize}
\end{itemize}

Theorems:

\begin{itemize}
	\item
\end{itemize}

\section{Information Theory}

Concepts:

\begin{itemize}
    \item Information $$h(A) = -log_2 p(A)$$ (bit)
    \item (Information Source) Entropy $$ H(X) = -\sum_{i=1}^n p(a_i)log_2p(a_i) \leq log_2 n$$ Maximize under equal probability
    \item Conditional Entropy $$H(Y|X)  = -\sum_{i=1}^n p(x_i)H(Y|X=x_i)= -\sum_{i=1}^n p(x_i)\sum_{j=1}^n p(y_j|x_i) log_2p(y_j|x_i) $$ $$ = \sum_{i=1}^n \sum_{j=1}^n p(x_i,y_j) log_2p(y_j|x_i) $$
    \item Mutual Information/Information Gain $$I(X;Y) = H(Y) - H(Y|X)$$
    \item Kullback-Leibler Divergence (K-L) Divergence $$D_{KL}(P||Q) = \sum_{i=1}^n p(x_i) log_2\frac{p(x_i)}{q(x_i)} \neq D_{KL}(Q||P)$$
    	Measures the Distance of two distributions. The optimal encoding of information has the same bits as the entropy. Measures the extra bits if the real distribution is q rather than p. (Using P to approximate Q)
\end{itemize}


Theorems:

\begin{itemize}
    \item The Maximum Entropy Principle. Without extra assumption, max entropy/equal probability has the minimum prediction risk. 
\end{itemize}

\section{Formal Logic}

Concepts
\begin{itemize}
    \item Generative Expert System: Rule+Facts+Deduction Engine 
    \item Godel's incompleteness theorems
\end{itemize}

\chapter{Computational Learning Theory}

\part{Supervised Learning Models}

\chapter{Regression}

\section{Linear Regressions}


\subsection{Assumptions}
Classic Assumptions for Statistics:
\begin{itemize}
    \item 
\end{itemize}

\subsection{Inteprataion}

$$ f(x) = \mathbf{w}^T \mathbf{x} = \sum_{i=1}^n w_i x_i $$
$$ \mathbf{w*} = (\mathbf{X^T X})^{-1} \mathbf{X^T y} $$

RSS Approach:


MLE Approach

Assuming noise is normal, maximize 

$$p(\mathbf{x_1, x_2 ... x_n}| \mathbf{ w} ) = \prod_k \frac{1}{\sqrt{2\pi} \sigma} exp[ -\frac{1}{2\sigma^2} (y_k - \mathbf{w_t x_k} )^2 ]$$ 

\subsection{Lasso-Least Absolute Shrinkage and Selection Operator}

$$ min ||y_k - \mathbf{w^T x}_k ||^2 + \lambda ||\mathbf{w}||_1 $$

\chapter{Logistic Regression and General Linear Model}

\chapter{Naive Bayesian}

\chapter{Tree Models and Ensemble Learning}

\part{Unsupervised Learning Models}

\chapter{Clustering}

\chapter{Dimension Reduction}



\part{Deep Learning and Enhanced Learning Theory}

\chapter{Multi-layer Perceptron}

\chapter{Multi-layer Perceptron}

\chapter{Multi-layer Perceptron}

\chapter{Multi-layer Perceptron}

\chapter{Multi-layer Perceptron}

\chapter{Multi-layer Perceptron}

 
\end{document}                          % The required last line 